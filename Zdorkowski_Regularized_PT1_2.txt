Zdorkowski Findings for Regularization Exercise Part 1 and 2

--------------------- Part 1 Tasks 1-8 ---------------------

PS C:\Users\Commander\Documents\GitHub\mac-learn-pub> & C:/Users/Commander/AppData/Local/Programs/Python/Python312/python.exe c:/Users/Commander/Documents/GitHub/mac-learn-pub/regularization_PT1_Zdorkowski.py

=== Dataset ===
            ZXT            JAC           IFY           LFE  ...           XYE            CVS            RMJ           LVT
0   -497.258055   97206.106650   3853.530879    125.165417  ...  -7342.664743    1783.101285  107103.442386 -1.106243e+08
1   1290.717217   59082.644125   -457.788437  -5131.012814  ...   1175.884998  -92105.292715  -81283.413905 -4.717735e+07
2   -763.739958  -39247.777789   6894.877155  -3389.857577  ... -10243.165179   24130.853672   27807.399740 -1.052511e+08
3    139.585886   44208.445670  10783.703933   5288.804798  ... -14856.387305   -2637.026941  164284.884156  1.990581e+07
4   1175.259008   32817.690795 -10235.374720  10811.783557  ...   9229.944892  -13608.783283  103506.077404  9.250613e+07
5    899.214987  -52217.016766   2728.121540   -585.436550  ...   4325.575803   59018.829505  113211.624296 -6.469042e+07
6   1158.249471   12186.820172   6848.960001   4437.480170  ...  -7071.275292   60255.959026   -8404.862255  1.265231e+08
7    411.703971  -35308.619432  -4653.356165 -16772.279195  ...    922.182779   26023.755801  190531.120143 -3.972655e+07
8    402.124785  -98057.458526   9162.735232  -8302.513766  ...  -9326.285709 -154120.656211 -115720.761929  1.712347e+07
9    577.825257  116806.185076  11313.679163   5853.486728  ...    284.520207   24698.872642   60330.156007  1.938883e+08
10  -289.538680   57074.013312  10579.868392  -6629.810367  ...  -1127.115429 -104404.825723  142346.973961 -6.239123e+07
11  -850.263655  105439.814711   3791.584473  -8986.171301  ...  12436.146324  -89530.589070  263500.366244 -3.197865e+07
12  -750.909276   95515.596452 -12229.936192   6651.081962  ...  -9180.779817   45129.340285 -160577.783246  9.373011e+07
13  -879.183440   71656.041767 -15937.590032  20204.362355  ...  19870.804578    4245.185688    7209.873131  8.925155e+07
14  -655.591970  -33512.578764 -11130.855364  -5318.191340  ...    -14.830947   26783.411595  -61325.363123  5.677250e+07

[15 rows x 112 columns]

=== Info ===
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 15 entries, 0 to 14
Columns: 112 entries, ZXT to LVT
dtypes: float64(112)
memory usage: 13.3 KB
None

Response describe() for LVT:
count    1.500000e+01
mean     1.519076e+07
std      9.086101e+07
min     -1.106243e+08
25%     -5.478429e+07
50%      1.712347e+07
75%      9.087884e+07
max      1.938883e+08
Name: LVT, dtype: float64

Linear RMSE: 77,512,195.48
Lasso RMSE: 1,313,963.54
Ridge RMSE: 77,512,195.48

=== Correlation Matrix === SEE Part1.png
          ZXT       JAC       IFY       LFE       RUM       GKL  ...       WPY       PMV       XYE       CVS       RMJ       LVT
ZXT  1.000000 -0.232206  0.223229 -0.023453 -0.344033 -0.313966  ... -0.205533  0.003706 -0.051954 -0.000937 -0.040530  0.209268   
JAC -0.232206  1.000000 -0.059175  0.417277 -0.032674  0.020614  ... -0.080290  0.285706  0.240275  0.026029  0.197212  0.256374   
IFY  0.223229 -0.059175  1.000000 -0.352175 -0.235146  0.103759  ...  0.050892  0.054073 -0.517396 -0.299460  0.305045 -0.235343   
LFE -0.023453  0.417277 -0.352175  1.000000 -0.091910  0.088002  ...  0.143557 -0.189597  0.256917  0.372085 -0.223043  0.579308   
RUM -0.344033 -0.032674 -0.235146 -0.091910  1.000000  0.290263  ... -0.633445  0.359543 -0.229638  0.170643 -0.072084 -0.397594   
..        ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...       ...       ...   
PMV  0.003706  0.285706  0.054073 -0.189597  0.359543 -0.060042  ... -0.514935  1.000000 -0.030633 -0.247735  0.425470 -0.340513   
XYE -0.051954  0.240275 -0.517396  0.256917 -0.229638  0.097159  ...  0.352756 -0.030633  1.000000 -0.070833  0.278575  0.152087   
CVS -0.000937  0.026029 -0.299460  0.372085  0.170643 -0.212729  ...  0.133546 -0.247735 -0.070833  1.000000 -0.009853  0.280546   
RMJ -0.040530  0.197212  0.305045 -0.223043 -0.072084  0.363659  ...  0.153360  0.425470  0.278575 -0.009853  1.000000 -0.331640   
LVT  0.209268  0.256374 -0.235343  0.579308 -0.397594 -0.249527  ...  0.148988 -0.340513  0.152087  0.280546 -0.331640  1.000000   

[112 rows x 112 columns]

--------------------- Part 1 Task 9 ---------------------

=== Dataset ===
            ZXT            JAC           IFY           LFE  ...           XYE            CVS            RMJ           LVT
0   -497.258055   97206.106650   3853.530879    125.165417  ...  -7342.664743    1783.101285  107103.442386 -1.106243e+08
1   1290.717217   59082.644125   -457.788437  -5131.012814  ...   1175.884998  -92105.292715  -81283.413905 -4.717735e+07
2   -763.739958  -39247.777789   6894.877155  -3389.857577  ... -10243.165179   24130.853672   27807.399740 -1.052511e+08
3    139.585886   44208.445670  10783.703933   5288.804798  ... -14856.387305   -2637.026941  164284.884156  1.990581e+07
4   1175.259008   32817.690795 -10235.374720  10811.783557  ...   9229.944892  -13608.783283  103506.077404  9.250613e+07
5    899.214987  -52217.016766   2728.121540   -585.436550  ...   4325.575803   59018.829505  113211.624296 -6.469042e+07
6   1158.249471   12186.820172   6848.960001   4437.480170  ...  -7071.275292   60255.959026   -8404.862255  1.265231e+08
7    411.703971  -35308.619432  -4653.356165 -16772.279195  ...    922.182779   26023.755801  190531.120143 -3.972655e+07
8    402.124785  -98057.458526   9162.735232  -8302.513766  ...  -9326.285709 -154120.656211 -115720.761929  1.712347e+07
9    577.825257  116806.185076  11313.679163   5853.486728  ...    284.520207   24698.872642   60330.156007  1.938883e+08
10  -289.538680   57074.013312  10579.868392  -6629.810367  ...  -1127.115429 -104404.825723  142346.973961 -6.239123e+07
11  -850.263655  105439.814711   3791.584473  -8986.171301  ...  12436.146324  -89530.589070  263500.366244 -3.197865e+07
12  -750.909276   95515.596452 -12229.936192   6651.081962  ...  -9180.779817   45129.340285 -160577.783246  9.373011e+07
13  -879.183440   71656.041767 -15937.590032  20204.362355  ...  19870.804578    4245.185688    7209.873131  8.925155e+07
14  -655.591970  -33512.578764 -11130.855364  -5318.191340  ...    -14.830947   26783.411595  -61325.363123  5.677250e+07

[15 rows x 112 columns]

=== Info ===
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 15 entries, 0 to 14
Columns: 112 entries, ZXT to LVT
dtypes: float64(112)
memory usage: 13.3 KB
None

Response describe() for LVT:
count    1.500000e+01
mean     1.519076e+07
std      9.086101e+07
min     -1.106243e+08
25%     -5.478429e+07
50%      1.712347e+07
75%      9.087884e+07
max      1.938883e+08
Name: LVT, dtype: float64

Linear RMSE: 67,690,525.40
Lasso RMSE: 2,295,549.79
Ridge RMSE: 67,690,525.40

=== Correlation Matrix ===
          ZXT       JAC       IFY       LFE       RUM       GKL  ...       WPY       PMV       XYE       CVS       RMJ       LVT
ZXT  1.000000 -0.232206  0.223229 -0.023453 -0.344033 -0.313966  ... -0.205533  0.003706 -0.051954 -0.000937 -0.040530  0.209268   
JAC -0.232206  1.000000 -0.059175  0.417277 -0.032674  0.020614  ... -0.080290  0.285706  0.240275  0.026029  0.197212  0.256374   
IFY  0.223229 -0.059175  1.000000 -0.352175 -0.235146  0.103759  ...  0.050892  0.054073 -0.517396 -0.299460  0.305045 -0.235343   
LFE -0.023453  0.417277 -0.352175  1.000000 -0.091910  0.088002  ...  0.143557 -0.189597  0.256917  0.372085 -0.223043  0.579308   
RUM -0.344033 -0.032674 -0.235146 -0.091910  1.000000  0.290263  ... -0.633445  0.359543 -0.229638  0.170643 -0.072084 -0.397594   
..        ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...       ...       ...   
PMV  0.003706  0.285706  0.054073 -0.189597  0.359543 -0.060042  ... -0.514935  1.000000 -0.030633 -0.247735  0.425470 -0.340513   
XYE -0.051954  0.240275 -0.517396  0.256917 -0.229638  0.097159  ...  0.352756 -0.030633  1.000000 -0.070833  0.278575  0.152087   
CVS -0.000937  0.026029 -0.299460  0.372085  0.170643 -0.212729  ...  0.133546 -0.247735 -0.070833  1.000000 -0.009853  0.280546   
RMJ -0.040530  0.197212  0.305045 -0.223043 -0.072084  0.363659  ...  0.153360  0.425470  0.278575 -0.009853  1.000000 -0.331640   
LVT  0.209268  0.256374 -0.235343  0.579308 -0.397594 -0.249527  ...  0.148988 -0.340513  0.152087  0.280546 -0.331640  1.000000   

[112 rows x 112 columns]


Part 1 Conclusion:
There is essentially no strong correlation structure in this data.
The correlation matrix confirms that only a few predictors show any meaningful correlation, and even those are weak.

When the random_state parameter is removed from train_test_split, the model receives a different train/test split each time. 
Because the dataset is small, these different splits can produce noticeably different RMSE values.

Ridge regression works well on this dataset because it handles many (weakly) correlated predictors without eliminating them.
Ridge stabilizes the model by shrinking coefficients instead of dropping variables, which allows it to manage noisy predictors 
more robustly than linear regression.


--------------------- Part 2 Tasks  ---------------------

PS C:\Users\Commander\Documents\GitHub\mac-learn-pub> & C:/Users/Commander/AppData/Local/Programs/Python/Python312/python.exe c:/Users/Commander/Documents/GitHub/mac-learn-pub/regularization_PT2_zdorkowski.py

=== First few rows ===
              x0           x1          x2         x3         x4  ...          x997       x998        x999      x1000           y
0  105641.205692   420.717074  372.704512  20.098777  15.918625  ...  12059.078874  91.310064  149.539639  21.571842   19.220505
1   23979.154939   -36.551220  508.462823  19.963592  15.431920  ...  -1625.978839  79.661956  151.617384  19.612784  869.605545
2   58621.182299  1203.290304  -21.960801  20.424596  20.210945  ...   3205.316493  38.055792  162.735905  21.502878  377.220936
3  134191.642515  -255.848814  190.657814  19.495905  17.480405  ...   -265.093421  57.363456  158.541594  20.970530 -956.473428
4  111838.517301  -380.025906  240.416437  19.189721  19.865868  ...   4905.514042  31.185651  141.168589  20.128882   34.285491

[5 rows x 1002 columns]

=== Last few rows ===
               x0           x1          x2         x3         x4  ...          x997       x998        x999      x1000           y
495  -4406.090408   453.767832  680.354605  20.183288  22.775765  ... -20370.426914  55.055186  158.928588  19.018749 -564.357741
496 -39410.208125  -216.570809   51.874024  21.487060  21.678045  ... -41708.793398  39.903759  152.660651  19.087239   68.630182
497 -30769.231815   104.294400   48.849532  20.243971  23.174560  ...  25952.449371  91.999792  144.861246  21.767020  -33.827958  
498 -60934.297976 -1257.508215 -287.024952  18.943636  21.911180  ...  -1998.256167  58.211087  143.908647  18.455205   65.532406  
499  -4641.401153  -391.719770  102.331283  18.774567  17.437475  ...  43094.313405  54.683415  141.179617  21.215259  360.660484  

[5 rows x 1002 columns]

=== Pearson Correlation of each feature with y ===
y       1.000000
x290    0.190111
x79     0.176643
x633    0.167491
x61     0.160459
          ...
x697   -0.114360
x958   -0.115473
x975   -0.115848
x258   -0.121468
x137   -0.150777
Name: y, Length: 1002, dtype: float64

=== Full Correlation Matrix === See Part2.png
             x0        x1        x2        x3        x4        x5  ...      x996      x997      x998      x999     x1000         y
x0     1.000000 -0.040796 -0.046299 -0.050678  0.017510  0.101964  ... -0.007249  0.057110  0.007350  0.029204 -0.034014 -0.052356 
x1    -0.040796  1.000000 -0.009084 -0.017144 -0.036981 -0.096843  ...  0.050027 -0.011672  0.075135  0.032272  0.077766  0.006096 
x2    -0.046299 -0.009084  1.000000 -0.048041 -0.006567  0.053486  ... -0.001596 -0.024154  0.006628  0.030353 -0.000367  0.079405 
x3    -0.050678 -0.017144 -0.048041  1.000000  0.045538  0.004671  ... -0.087092  0.014636  0.028407 -0.007918 -0.024238 -0.022916 
x4     0.017510 -0.036981 -0.006567  0.045538  1.000000  0.008074  ...  0.024567  0.002342 -0.049912 -0.076827  0.013874 -0.018079 
...         ...       ...       ...       ...       ...       ...  ...       ...       ...       ...       ...       ...       ... 
x997   0.057110 -0.011672 -0.024154  0.014636  0.002342 -0.021929  ... -0.016204  1.000000  0.022297  0.025526  0.061049  0.021776 
x998   0.007350  0.075135  0.006628  0.028407 -0.049912  0.034165  ...  0.016596  0.022297  1.000000 -0.007599 -0.028484  0.026914 
x999   0.029204  0.032272  0.030353 -0.007918 -0.076827 -0.043606  ... -0.002578  0.025526 -0.007599  1.000000  0.020165  0.048909 
x1000 -0.034014  0.077766 -0.000367 -0.024238  0.013874  0.008406  ... -0.042288  0.061049 -0.028484  0.020165  1.000000 -0.030419 
y     -0.052356  0.006096  0.079405 -0.022916 -0.018079 -0.040759  ... -0.037777  0.021776  0.026914  0.048909 -0.030419  1.000000 

[1002 rows x 1002 columns]

Linear Regression RMSE: 1,184.348
Lasso Regression RMSE: 461.776
Ridge Regression RMSE: 1,184.348

Part 2 Conclusion:
The strongest correlation in the entire dataset was ~0.19, meaning none of the predictors individually explain much of the variability in y.
This is why the full correlation heatmap looks like TV static â€” almost everything is effectively uncorrelated with everything else.

However, Lasso performed dramatically better than Linear or Ridge regression because only a very small subset of features actually contributes
to creating meaningful patterns. With over 1000 features and only 500 samples, the model is in a high-dimensional regime where most predictors 
are noise - ripe for lasso. Lasso excels in this situation because it shrinks irrelevant coefficients to zero, effectively performing feature selection.
This allows the model to focus only on the small number of truly important predictors, dramatically reducing RMSE.